# é˜¿é‡Œå·´å·´å¤§æ•°æ®å¤„ç†é¢è¯•é¢˜

## ğŸ“š é¢˜ç›®æ¦‚è§ˆ

é˜¿é‡Œå·´å·´å¤§æ•°æ®å¤„ç†é¢è¯•é‡ç‚¹è€ƒå¯Ÿåœ¨å¤§è§„æ¨¡æ•°æ®å¤„ç†åœºæ™¯ä¸‹çš„æŠ€æœ¯èƒ½åŠ›ï¼Œä¸»è¦æ¶‰åŠHadoopç”Ÿæ€ã€Sparkã€Flinkå®æ—¶è®¡ç®—ã€æ•°æ®ä»“åº“å»ºè®¾ç­‰æ ¸å¿ƒæŠ€æœ¯ã€‚

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯è€ƒå¯Ÿé‡ç‚¹

### åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
- **Hadoopç”Ÿæ€** - HDFSã€MapReduceã€YARNèµ„æºç®¡ç†
- **Sparkè®¡ç®—** - RDDã€DataFrameã€Streamingã€SQL
- **Flinkå®æ—¶** - æµå¤„ç†ã€çª—å£è®¡ç®—ã€çŠ¶æ€ç®¡ç†
- **æ•°æ®å­˜å‚¨** - HBaseã€Hiveã€ClickHouseã€MaxCompute

### å®æ—¶æ•°æ®å¤„ç†
- **æµå¼è®¡ç®—** - äº‹ä»¶æ—¶é—´ã€æ°´å°æœºåˆ¶ã€å®¹é”™æ¢å¤
- **æ•°æ®åŒæ­¥** - CDCã€Binlogè§£æã€å®æ—¶ETL
- **è®¡ç®—ä¼˜åŒ–** - åå‹æ§åˆ¶ã€æ£€æŸ¥ç‚¹ã€çŠ¶æ€åç«¯
- **ç›‘æ§è¿ç»´** - ä½œä¸šç›‘æ§ã€æ€§èƒ½è°ƒä¼˜ã€æ•…éšœå¤„ç†

## ğŸ“ æ ¸å¿ƒé¢è¯•é¢˜ç›®

### 1. åŒåä¸€å®æ—¶æ•°æ®å¤§å±æ¶æ„è®¾è®¡

#### é¢˜ç›®1ï¼šå®æ—¶GMVè®¡ç®—ç³»ç»Ÿè®¾è®¡
**é—®é¢˜**ï¼šè®¾è®¡åŒåä¸€å®æ—¶GMVå¤§å±ç³»ç»Ÿï¼Œè¦æ±‚ç§’çº§æ›´æ–°ï¼Œæ”¯æŒå¤šç»´åº¦ç»Ÿè®¡ï¼ˆåœ°åŒºã€å“ç±»ã€åº—é“ºï¼‰ã€‚

**æ¶æ„è®¾è®¡**ï¼š
```mermaid
graph LR
    A[è®¢å•ç³»ç»Ÿ] --> B[Kafkaé›†ç¾¤]
    C[æ”¯ä»˜ç³»ç»Ÿ] --> B
    D[é€€æ¬¾ç³»ç»Ÿ] --> B
    
    B --> E[Flinkå®æ—¶è®¡ç®—]
    E --> F[Redisé›†ç¾¤]
    E --> G[ClickHouse]
    
    F --> H[å®æ—¶å¤§å±]
    G --> I[OLAPåˆ†æ]
    
    subgraph "å®æ—¶è®¡ç®—å±‚"
        E --> J[è®¢å•æµå¤„ç†]
        E --> K[æ”¯ä»˜æµå¤„ç†] 
        E --> L[é€€æ¬¾æµå¤„ç†]
        E --> M[GMVèšåˆè®¡ç®—]
    end
```

**æ ¸å¿ƒå®ç°**ï¼š
```java
// Flinkå®æ—¶GMVè®¡ç®—
public class RealtimeGMVJob {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // è®¾ç½®æ£€æŸ¥ç‚¹
        env.enableCheckpointing(5000);
        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
        
        // è®¢å•æµ
        DataStream<OrderEvent> orderStream = env
            .addSource(new FlinkKafkaConsumer<>("order-topic", new OrderEventSchema(), 
                getKafkaProperties()))
            .assignTimestampsAndWatermarks(
                WatermarkStrategy.<OrderEvent>forBoundedOutOfOrderness(Duration.ofSeconds(5))
                    .withTimestampAssigner((event, timestamp) -> event.getEventTime()));
        
        // æ”¯ä»˜æµ
        DataStream<PaymentEvent> paymentStream = env
            .addSource(new FlinkKafkaConsumer<>("payment-topic", new PaymentEventSchema(), 
                getKafkaProperties()))
            .assignTimestampsAndWatermarks(
                WatermarkStrategy.<PaymentEvent>forBoundedOutOfOrderness(Duration.ofSeconds(5))
                    .withTimestampAssigner((event, timestamp) -> event.getEventTime()));
        
        // è®¡ç®—å®æ—¶GMV
        DataStream<GMVResult> gmvStream = orderStream
            .connect(paymentStream)
            .process(new GMVCalculationFunction())
            .keyBy(GMVResult::getRegion)
            .window(TumblingEventTimeWindows.of(Time.seconds(10)))
            .aggregate(new GMVAggregateFunction(), new GMVWindowFunction());
        
        // è¾“å‡ºåˆ°Rediså’ŒClickHouse
        gmvStream.addSink(new RedisSink<>());
        gmvStream.addSink(new ClickHouseSink<>());
        
        env.execute("Realtime GMV Job");
    }
}

// GMVèšåˆå‡½æ•°
public class GMVAggregateFunction implements AggregateFunction<GMVResult, GMVAccumulator, GMVResult> {
    
    @Override
    public GMVAccumulator createAccumulator() {
        return new GMVAccumulator();
    }
    
    @Override
    public GMVAccumulator add(GMVResult value, GMVAccumulator accumulator) {
        accumulator.addGMV(value.getAmount());
        accumulator.addOrderCount(value.getOrderCount());
        return accumulator;
    }
    
    @Override
    public GMVResult getResult(GMVAccumulator accumulator) {
        return GMVResult.builder()
            .totalGMV(accumulator.getTotalGMV())
            .orderCount(accumulator.getOrderCount())
            .avgOrderValue(accumulator.getTotalGMV() / accumulator.getOrderCount())
            .build();
    }
    
    @Override
    public GMVAccumulator merge(GMVAccumulator a, GMVAccumulator b) {
        a.merge(b);
        return a;
    }
}
```

### 2. ç¦»çº¿æ•°æ®ä»“åº“å»ºè®¾

#### é¢˜ç›®2ï¼šç”µå•†æ•°æ®ä»“åº“åˆ†å±‚æ¶æ„
**é—®é¢˜**ï¼šè®¾è®¡ç”µå•†æ•°æ®ä»“åº“çš„åˆ†å±‚æ¶æ„ï¼ŒåŒ…æ‹¬ODSã€DWDã€DWSã€ADSå±‚çš„è®¾è®¡åŸåˆ™ã€‚

**æ•°æ®ä»“åº“æ¶æ„**ï¼š
```mermaid
graph TB
    subgraph "æ•°æ®æºå±‚"
        A[è®¢å•ç³»ç»Ÿ]
        B[ç”¨æˆ·ç³»ç»Ÿ] 
        C[å•†å“ç³»ç»Ÿ]
        D[æ—¥å¿—æ•°æ®]
    end
    
    subgraph "ODSå±‚-åŸå§‹æ•°æ®"
        E[ods_order_info]
        F[ods_user_info]
        G[ods_product_info]
        H[ods_log_data]
    end
    
    subgraph "DWDå±‚-æ˜ç»†æ•°æ®"
        I[dwd_order_detail]
        J[dwd_user_action]
        K[dwd_product_detail]
    end
    
    subgraph "DWSå±‚-æ±‡æ€»æ•°æ®"
        L[dws_user_action_daycount]
        M[dws_product_stats_daycount]
        N[dws_area_stats_daycount]
    end
    
    subgraph "ADSå±‚-åº”ç”¨æ•°æ®"
        O[ads_gmv_stats]
        P[ads_user_stats]
        Q[ads_product_ranking]
    end
    
    A --> E
    B --> F
    C --> G
    D --> H
    
    E --> I
    F --> I
    G --> K
    H --> J
    
    I --> L
    I --> M
    J --> L
    K --> M
    
    L --> O
    L --> P
    M --> Q
```

### 3. æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹

#### é¢˜ç›®3ï¼šSparkä½œä¸šæ€§èƒ½è°ƒä¼˜
**é—®é¢˜**ï¼šä¸€ä¸ªSparkä½œä¸šå¤„ç†100TBæ•°æ®è€—æ—¶8å°æ—¶ï¼Œå¦‚ä½•ä¼˜åŒ–åˆ°2å°æ—¶å†…å®Œæˆï¼Ÿ

**ä¼˜åŒ–ç­–ç•¥**ï¼š
1. **æ•°æ®å€¾æ–œä¼˜åŒ–**ï¼šåŠ ç›å¤„ç†ã€é¢„èšåˆ
2. **å†…å­˜ç®¡ç†**ï¼šè°ƒæ•´executorå†…å­˜ã€å¼€å¯åŠ¨æ€åˆ†é…
3. **åºåˆ—åŒ–ä¼˜åŒ–**ï¼šä½¿ç”¨Kryoåºåˆ—åŒ–
4. **å¹¶è¡Œåº¦è°ƒæ•´**ï¼šå¢åŠ åˆ†åŒºæ•°ã€åˆç†è®¾ç½®å¹¶è¡Œåº¦
5. **å­˜å‚¨æ ¼å¼**ï¼šä½¿ç”¨Parquetæ ¼å¼ã€å¯ç”¨å‹ç¼©

## ğŸ“Š é¢è¯•è¯„åˆ†æ ‡å‡†

### å¤§æ•°æ®ç†è®ºåŸºç¡€ (30%)
- **åˆ†å¸ƒå¼è®¡ç®—åŸç†**ï¼šMapReduceã€Sparkã€Flinkè®¡ç®—æ¨¡å‹
- **æ•°æ®å­˜å‚¨ç†è§£**ï¼šHDFSã€HBaseã€åˆ—å¼å­˜å‚¨åŸç†
- **æµè®¡ç®—æ¦‚å¿µ**ï¼šäº‹ä»¶æ—¶é—´ã€æ°´å°ã€çŠ¶æ€ç®¡ç†
- **æ•°æ®ä»“åº“ç†è®º**ï¼šç»´åº¦å»ºæ¨¡ã€åˆ†å±‚æ¶æ„ã€æ•°æ®æ²»ç†

### æŠ€æœ¯å®ç°èƒ½åŠ› (35%)
- **ç¼–ç¨‹èƒ½åŠ›**ï¼šScala/Javaç¼–ç¨‹ã€SQLä¼˜åŒ–
- **æ¡†æ¶ä½¿ç”¨**ï¼šSpark/Flinkå¼€å‘ç»éªŒ
- **æ€§èƒ½è°ƒä¼˜**ï¼šä½œä¸šä¼˜åŒ–ã€èµ„æºè°ƒä¼˜ç»éªŒ
- **é—®é¢˜æ’æŸ¥**ï¼šå¤§æ•°æ®ä½œä¸šé—®é¢˜å®šä½èƒ½åŠ›

### æ¶æ„è®¾è®¡èƒ½åŠ› (25%)
- **ç³»ç»Ÿè®¾è®¡**ï¼šå¤§æ•°æ®å¹³å°æ¶æ„è®¾è®¡
- **æŠ€æœ¯é€‰å‹**ï¼šåˆé€‚çš„æŠ€æœ¯æ ˆé€‰æ‹©
- **æ‰©å±•æ€§è€ƒè™‘**ï¼šç³»ç»Ÿæ‰©å±•å’Œæ¼”è¿›è§„åˆ’
- **æˆæœ¬æ§åˆ¶**ï¼šèµ„æºä½¿ç”¨å’Œæˆæœ¬ä¼˜åŒ–

### ä¸šåŠ¡ç†è§£ (10%)
- **ç”µå•†åœºæ™¯**ï¼šå¯¹ç”µå•†å¤§æ•°æ®åœºæ™¯çš„ç†è§£
- **æŒ‡æ ‡ä½“ç³»**ï¼šæ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡çš„ç†è§£
- **æ•°æ®è´¨é‡**ï¼šæ•°æ®è´¨é‡ä¿éšœæ„è¯†
- **ä¸šåŠ¡ä»·å€¼**ï¼šæŠ€æœ¯æ–¹æ¡ˆçš„ä¸šåŠ¡ä»·å€¼

## ğŸ¯ å¤‡è€ƒå»ºè®®

### æŠ€æœ¯èƒ½åŠ›æå‡
1. **ç†è®ºå­¦ä¹ **ï¼šæ·±å…¥å­¦ä¹ Hadoopã€Sparkã€Flinkæ ¸å¿ƒåŸç†
2. **åŠ¨æ‰‹å®è·µ**ï¼šæ­å»ºå¤§æ•°æ®ç¯å¢ƒï¼Œå®Œæˆç«¯åˆ°ç«¯é¡¹ç›®
3. **æ€§èƒ½è°ƒä¼˜**ï¼šå­¦ä¹ å„ç§æ€§èƒ½ä¼˜åŒ–æŠ€å·§å’Œæœ€ä½³å®è·µ
4. **æºç é˜…è¯»**ï¼šé˜…è¯»Sparkã€Flinkç­‰æ¡†æ¶æºç 

### é¡¹ç›®ç»éªŒç§¯ç´¯
1. **å®æ—¶è®¡ç®—é¡¹ç›®**ï¼šåŸºäºFlinkçš„å®æ—¶æ•°æ®å¤„ç†é¡¹ç›®
2. **ç¦»çº¿åˆ†æé¡¹ç›®**ï¼šåŸºäºSparkçš„å¤§è§„æ¨¡æ•°æ®åˆ†æé¡¹ç›®
3. **æ•°æ®ä»“åº“é¡¹ç›®**ï¼šå®Œæ•´çš„æ•°æ®ä»“åº“å»ºè®¾é¡¹ç›®
4. **ä¼˜åŒ–æ¡ˆä¾‹**ï¼šå¤§æ•°æ®ä½œä¸šæ€§èƒ½ä¼˜åŒ–å®æˆ˜

### é˜¿é‡ŒæŠ€æœ¯å­¦ä¹ 
- **MaxCompute**ï¼šå­¦ä¹ é˜¿é‡Œäº‘å¤§æ•°æ®è®¡ç®—æœåŠ¡
- **DataWorks**ï¼šäº†è§£é˜¿é‡Œæ•°æ®å¼€å‘å¹³å°
- **å®æ—¶è®¡ç®—**ï¼šå­¦ä¹ é˜¿é‡Œäº‘FlinkæœåŠ¡
- **æœ€ä½³å®è·µ**ï¼šå­¦ä¹ é˜¿é‡Œå¤§æ•°æ®æœ€ä½³å®è·µæ¡ˆä¾‹

---
[â† è¿”å›é˜¿é‡Œå·´å·´é¢è¯•é¢˜åº“](./README.md) 