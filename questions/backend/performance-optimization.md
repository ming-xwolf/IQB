# æ€§èƒ½ä¼˜åŒ–é¢è¯•é¢˜

[â† è¿”å›åç«¯é¢è¯•é¢˜ç›®å½•](./README.md)

## ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹

- æ€§èƒ½åˆ†ææ–¹æ³•
- ä»£ç å±‚é¢ä¼˜åŒ–
- æ•°æ®åº“ä¼˜åŒ–
- æ¶æ„ä¼˜åŒ–
- ç¼“å­˜ç­–ç•¥
- è´Ÿè½½å‡è¡¡
- ç›‘æ§ä¸è¯Šæ–­
- æ€§èƒ½æµ‹è¯•

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–é‡‘å­—å¡”

```mermaid
graph TD
    A[æ€§èƒ½ä¼˜åŒ–ç­–ç•¥] --> B[ä»£ç ä¼˜åŒ–]
    A --> C[æ•°æ®åº“ä¼˜åŒ–] 
    A --> D[æ¶æ„ä¼˜åŒ–]
    A --> E[åŸºç¡€è®¾æ–½ä¼˜åŒ–]
    
    B --> B1[ç®—æ³•ä¼˜åŒ–]
    B --> B2[å†…å­˜ç®¡ç†]
    B --> B3[å¹¶å‘å¤„ç†]
    
    C --> C1[æŸ¥è¯¢ä¼˜åŒ–]
    C --> C2[ç´¢å¼•è®¾è®¡]
    C --> C3[è¿æ¥æ± ]
    
    D --> D1[ç¼“å­˜æ¶æ„]
    D --> D2[è´Ÿè½½å‡è¡¡]
    D --> D3[å¾®æœåŠ¡]
    
    E --> E1[æœåŠ¡å™¨é…ç½®]
    E --> E2[ç½‘ç»œä¼˜åŒ–]
    E --> E3[CDN]
```

## ğŸ’¡ é¢è¯•é¢˜ç›®

### **åˆçº§é¢˜ç›®**

#### 1. ä»€ä¹ˆæ˜¯æ€§èƒ½ä¼˜åŒ–ï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- æ€§èƒ½ä¼˜åŒ–çš„å®šä¹‰ï¼šæé«˜ç³»ç»Ÿå“åº”é€Ÿåº¦ã€ååé‡ã€å‡å°‘èµ„æºæ¶ˆè€—
- é‡è¦æ€§ï¼š
  - ç”¨æˆ·ä½“éªŒæå‡
  - èµ„æºæˆæœ¬èŠ‚çœ
  - ç³»ç»Ÿç¨³å®šæ€§
  - ç«äº‰ä¼˜åŠ¿

#### 2. å¸¸è§çš„æ€§èƒ½æŒ‡æ ‡æœ‰å“ªäº›ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **å“åº”æ—¶é—´**ï¼šç”¨æˆ·å‘èµ·è¯·æ±‚åˆ°æ”¶åˆ°å“åº”çš„æ—¶é—´
- **ååé‡**ï¼šå•ä½æ—¶é—´å†…å¤„ç†çš„è¯·æ±‚æ•°é‡
- **å¹¶å‘ç”¨æˆ·æ•°**ï¼šåŒæ—¶è®¿é—®ç³»ç»Ÿçš„ç”¨æˆ·æ•°
- **CPUä½¿ç”¨ç‡**ï¼šå¤„ç†å™¨åˆ©ç”¨ç‡
- **å†…å­˜ä½¿ç”¨ç‡**ï¼šå†…å­˜å ç”¨æƒ…å†µ
- **I/OæŒ‡æ ‡**ï¼šç£ç›˜å’Œç½‘ç»œI/Oæ€§èƒ½

```mermaid
pie title æ€§èƒ½é—®é¢˜åˆ†å¸ƒ
    "æ•°æ®åº“æŸ¥è¯¢" : 40
    "ç½‘ç»œå»¶è¿Ÿ" : 25
    "ä»£ç é€»è¾‘" : 20
    "ç³»ç»Ÿé…ç½®" : 15
```

#### 3. å¦‚ä½•è¯†åˆ«æ€§èƒ½ç“¶é¢ˆï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- æ€§èƒ½ç›‘æ§å·¥å…·
- æ—¥å¿—åˆ†æ
- APM(åº”ç”¨æ€§èƒ½ç›‘æ§)
- å‹åŠ›æµ‹è¯•
- æ€§èƒ½åˆ†æå™¨(Profiler)

### **ä¸­çº§é¢˜ç›®**

#### 4. æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–çš„å¸¸è§æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **ç´¢å¼•ä¼˜åŒ–**ï¼š
  - åˆ›å»ºåˆé€‚çš„ç´¢å¼•
  - é¿å…è¿‡å¤šç´¢å¼•
  - å¤åˆç´¢å¼•è®¾è®¡
  
- **æŸ¥è¯¢ä¼˜åŒ–**ï¼š
  - é¿å…SELECT *
  - ä½¿ç”¨LIMITåˆ†é¡µ
  - ä¼˜åŒ–JOINæ“ä½œ
  
- **æ¶æ„ä¼˜åŒ–**ï¼š
  - è¯»å†™åˆ†ç¦»
  - åˆ†åº“åˆ†è¡¨
  - ç¼“å­˜ç­–ç•¥

```sql
-- ä¼˜åŒ–å‰
SELECT * FROM users WHERE email LIKE '%@gmail.com' ORDER BY created_at;

-- ä¼˜åŒ–å
SELECT id, name, email FROM users 
WHERE email_domain = 'gmail.com' 
ORDER BY created_at 
LIMIT 20 OFFSET 0;

-- æ·»åŠ ç´¢å¼•
CREATE INDEX idx_email_domain_created ON users(email_domain, created_at);
```

#### 5. ç¼“å­˜ç­–ç•¥æœ‰å“ªäº›ï¼Ÿå¦‚ä½•é€‰æ‹©ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **ç¼“å­˜ç±»å‹**ï¼š
  - å†…å­˜ç¼“å­˜ (Redis, Memcached)
  - æœ¬åœ°ç¼“å­˜ (HashMap, LRU)
  - åˆ†å¸ƒå¼ç¼“å­˜
  - CDNç¼“å­˜
  
- **ç¼“å­˜ç­–ç•¥**ï¼š
  - Cache-Aside
  - Write-Through
  - Write-Behind
  - Refresh-Ahead

```mermaid
flowchart LR
    A[è¯·æ±‚] --> B{ç¼“å­˜å‘½ä¸­?}
    B -->|æ˜¯| C[è¿”å›ç¼“å­˜æ•°æ®]
    B -->|å¦| D[æŸ¥è¯¢æ•°æ®åº“]
    D --> E[æ›´æ–°ç¼“å­˜]
    E --> F[è¿”å›æ•°æ®]
```

#### 6. å¦‚ä½•ä¼˜åŒ–Javaåº”ç”¨çš„æ€§èƒ½ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **JVMä¼˜åŒ–**ï¼š
  - åƒåœ¾å›æ”¶å™¨é€‰æ‹©
  - å †å†…å­˜é…ç½®
  - JITç¼–è¯‘ä¼˜åŒ–
  
- **ä»£ç ä¼˜åŒ–**ï¼š
  - é¿å…å¯¹è±¡è¿‡åº¦åˆ›å»º
  - ä½¿ç”¨åˆé€‚çš„é›†åˆç±»
  - ä¼˜åŒ–å¾ªç¯å’Œæ¡ä»¶åˆ¤æ–­

```java
// ä¼˜åŒ–å‰ - å­—ç¬¦ä¸²æ‹¼æ¥
String result = "";
for (int i = 0; i < 10000; i++) {
    result += "item" + i;
}

// ä¼˜åŒ–å - ä½¿ç”¨StringBuilder
StringBuilder sb = new StringBuilder();
for (int i = 0; i < 10000; i++) {
    sb.append("item").append(i);
}
String result = sb.toString();

// JVMå‚æ•°ä¼˜åŒ–
// -Xms2g -Xmx4g -XX:+UseG1GC -XX:MaxGCPauseMillis=200
```

### **é«˜çº§é¢˜ç›®**

#### 7. å¾®æœåŠ¡æ¶æ„ä¸‹å¦‚ä½•è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **æœåŠ¡é—´é€šä¿¡ä¼˜åŒ–**ï¼š
  - gRPC vs REST
  - è¿æ¥æ± ç®¡ç†
  - å¼‚æ­¥é€šä¿¡
  
- **æœåŠ¡æ²»ç†**ï¼š
  - ç†”æ–­å™¨æ¨¡å¼
  - é™æµç­–ç•¥
  - è¶…æ—¶è®¾ç½®
  
- **æ•°æ®ä¸€è‡´æ€§**ï¼š
  - äº‹ä»¶é©±åŠ¨æ¶æ„
  - SAGAæ¨¡å¼
  - æœ€ç»ˆä¸€è‡´æ€§

```java
// Hystrixç†”æ–­å™¨ç¤ºä¾‹
@HystrixCommand(fallbackMethod = "getDefaultUser", 
    commandProperties = {
        @HystrixProperty(name = "execution.isolation.thread.timeoutInMilliseconds", value = "3000"),
        @HystrixProperty(name = "circuitBreaker.requestVolumeThreshold", value = "10"),
        @HystrixProperty(name = "circuitBreaker.errorThresholdPercentage", value = "50")
    })
public User getUserById(Long id) {
    return userService.findById(id);
}

public User getDefaultUser(Long id) {
    return new User(id, "Default User");
}
```

#### 8. å¦‚ä½•è®¾è®¡é«˜æ€§èƒ½çš„APIï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **APIè®¾è®¡åŸåˆ™**ï¼š
  - RESTfulè®¾è®¡
  - åˆ†é¡µå¤„ç†
  - å­—æ®µè¿‡æ»¤
  - ç‰ˆæœ¬æ§åˆ¶
  
- **æ€§èƒ½ä¼˜åŒ–**ï¼š
  - å“åº”å‹ç¼©
  - HTTPç¼“å­˜
  - å¼‚æ­¥å¤„ç†
  - æ‰¹é‡æ“ä½œ

```python
# FastAPIé«˜æ€§èƒ½APIç¤ºä¾‹
from fastapi import FastAPI, BackgroundTasks, Query
from typing import Optional, List
import asyncio

app = FastAPI()

@app.get("/users")
async def get_users(
    page: int = Query(1, ge=1),
    size: int = Query(10, ge=1, le=100),
    fields: Optional[str] = None
):
    # åˆ†é¡µæŸ¥è¯¢
    offset = (page - 1) * size
    users = await User.objects.offset(offset).limit(size)
    
    # å­—æ®µè¿‡æ»¤
    if fields:
        selected_fields = fields.split(',')
        users = [{k: v for k, v in user.dict().items() if k in selected_fields} for user in users]
    
    return {"users": users, "page": page, "size": size}

@app.post("/users/batch")
async def create_users_batch(users: List[dict], background_tasks: BackgroundTasks):
    # æ‰¹é‡åˆ›å»º
    created_users = await User.bulk_create(users)
    
    # å¼‚æ­¥åå¤„ç†
    background_tasks.add_task(send_welcome_emails, created_users)
    
    return {"created": len(created_users)}
```

#### 9. å¤§æ•°æ®åœºæ™¯ä¸‹çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **æ•°æ®å¤„ç†ä¼˜åŒ–**ï¼š
  - åˆ†ç‰‡(Sharding)
  - åˆ†åŒº(Partitioning)
  - æµå¼å¤„ç†
  - æ‰¹å¤„ç†ä¼˜åŒ–
  
- **å­˜å‚¨ä¼˜åŒ–**ï¼š
  - åˆ—å¼å­˜å‚¨
  - æ•°æ®å‹ç¼©
  - åˆ†å¸ƒå¼å­˜å‚¨
  - ç´¢å¼•è®¾è®¡

```python
# Apache Sparkæ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, sum

spark = SparkSession.builder \
    .appName("DataProcessingOptimization") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .getOrCreate()

# è¯»å–æ•°æ®æ—¶æŒ‡å®šåˆ†åŒº
df = spark.read.parquet("hdfs://data/transactions") \
    .filter(col("date") >= "2023-01-01") \
    .repartition(200, col("user_id"))

# ç¼“å­˜é¢‘ç¹ä½¿ç”¨çš„æ•°æ®
df_cached = df.cache()

# ä¼˜åŒ–èšåˆæ“ä½œ
result = df_cached.groupBy("user_id", "category") \
    .agg(count("*").alias("transaction_count"),
         sum("amount").alias("total_amount")) \
    .orderBy("total_amount", ascending=False)

result.write.mode("overwrite").parquet("hdfs://output/user_summary")
```

### **å®æˆ˜é¢˜ç›®**

#### 10. å®ç°ä¸€ä¸ªé«˜æ€§èƒ½çš„è®¡æ•°å™¨æœåŠ¡

```java
@Service
public class HighPerformanceCounter {
    private final RedisTemplate<String, String> redisTemplate;
    private final AtomicLong localCounter = new AtomicLong(0);
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
    
    // æ‰¹é‡æ›´æ–°ç­–ç•¥
    private final long BATCH_SIZE = 100;
    private final long FLUSH_INTERVAL = 5; // ç§’
    
    @PostConstruct
    public void init() {
        // å®šæ—¶æ‰¹é‡åŒæ­¥åˆ°Redis
        scheduler.scheduleAtFixedRate(this::flushToRedis, 
            FLUSH_INTERVAL, FLUSH_INTERVAL, TimeUnit.SECONDS);
    }
    
    public void increment(String key) {
        // æœ¬åœ°è®¡æ•°å™¨å¿«é€Ÿå“åº”
        localCounter.incrementAndGet();
        
        // å¼‚æ­¥æ‰¹é‡æ›´æ–°
        if (localCounter.get() % BATCH_SIZE == 0) {
            CompletableFuture.runAsync(() -> flushToRedis());
        }
    }
    
    private void flushToRedis() {
        long count = localCounter.getAndSet(0);
        if (count > 0) {
            redisTemplate.opsForValue().increment("global_counter", count);
        }
    }
    
    public long getCount() {
        // åˆå¹¶æœ¬åœ°å’Œè¿œç¨‹è®¡æ•°
        long localCount = localCounter.get();
        String redisCount = redisTemplate.opsForValue().get("global_counter");
        return localCount + (redisCount != null ? Long.parseLong(redisCount) : 0);
    }
}
```

#### 11. å®ç°æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

```java
@Configuration
public class DatabaseOptimizationConfig {
    
    @Bean
    @Primary
    public DataSource primaryDataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl("jdbc:mysql://localhost:3306/mydb");
        config.setUsername("user");
        config.setPassword("password");
        
        // è¿æ¥æ± ä¼˜åŒ–
        config.setMaximumPoolSize(20);
        config.setMinimumIdle(5);
        config.setConnectionTimeout(30000);
        config.setIdleTimeout(600000);
        config.setMaxLifetime(1800000);
        
        // SQLä¼˜åŒ–
        config.addDataSourceProperty("cachePrepStmts", "true");
        config.addDataSourceProperty("prepStmtCacheSize", "250");
        config.addDataSourceProperty("prepStmtCacheSqlLimit", "2048");
        config.addDataSourceProperty("useServerPrepStmts", "true");
        
        return new HikariDataSource(config);
    }
    
    @Bean
    public DataSource readOnlyDataSource() {
        // è¯»å†™åˆ†ç¦»é…ç½®
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl("jdbc:mysql://readonly-host:3306/mydb");
        config.setReadOnly(true);
        config.setMaximumPoolSize(15);
        
        return new HikariDataSource(config);
    }
}

@Repository
public class OptimizedUserRepository {
    
    @Autowired
    @Qualifier("primaryDataSource")
    private JdbcTemplate writeTemplate;
    
    @Autowired
    @Qualifier("readOnlyDataSource")
    private JdbcTemplate readTemplate;
    
    // æ‰¹é‡æ’å…¥ä¼˜åŒ–
    public void batchInsertUsers(List<User> users) {
        String sql = "INSERT INTO users (name, email, created_at) VALUES (?, ?, ?)";
        
        readTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() {
            @Override
            public void setValues(PreparedStatement ps, int i) throws SQLException {
                User user = users.get(i);
                ps.setString(1, user.getName());
                ps.setString(2, user.getEmail());
                ps.setTimestamp(3, Timestamp.valueOf(user.getCreatedAt()));
            }
            
            @Override
            public int getBatchSize() {
                return users.size();
            }
        });
    }
}
```

## ğŸ”— æ€§èƒ½ä¼˜åŒ–å·¥å…·

### ç›‘æ§å·¥å…·å¯¹æ¯”

```mermaid
graph TB
    A[æ€§èƒ½ç›‘æ§å·¥å…·] --> B[APMå·¥å…·]
    A --> C[æ—¥å¿—åˆ†æ]
    A --> D[æ€§èƒ½æµ‹è¯•]
    
    B --> B1[New Relic]
    B --> B2[AppDynamics]
    B --> B3[Skywalking]
    
    C --> C1[ELK Stack]
    C --> C2[Fluentd]
    C --> C3[Grafana]
    
    D --> D1[JMeter]
    D --> D2[Gatling]
    D --> D3[K6]
```

### ç›¸å…³ä¸»é¢˜
- [ç¼“å­˜æŠ€æœ¯é¢è¯•é¢˜](./caching.md)
- [æ•°æ®åº“ä¼˜åŒ–é¢è¯•é¢˜](../database/README.md)
- [å¾®æœåŠ¡æ¶æ„é¢è¯•é¢˜](./microservices.md)
- [ç³»ç»Ÿè®¾è®¡é¢è¯•é¢˜](../system-design/README.md)

## ğŸ“š æ¨èèµ„æº

### ä¹¦ç±æ¨è
- ã€Šé«˜æ€§èƒ½MySQLã€‹
- ã€ŠJavaæ€§èƒ½æƒå¨æŒ‡å—ã€‹
- ã€Šæ€§èƒ½ä¹‹å·…ï¼šæ´æ‚‰ç³»ç»Ÿã€ä¼ä¸šä¸äº‘è®¡ç®—ã€‹

### åœ¨çº¿èµ„æº
- [Google Web Fundamentals](https://developers.google.com/web/fundamentals/performance)
- [High Scalability](http://highscalability.com/)

---

*æ€§èƒ½ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦åœ¨è®¾è®¡ã€å¼€å‘ã€éƒ¨ç½²çš„å„ä¸ªé˜¶æ®µéƒ½è¦è€ƒè™‘* ğŸš€ 