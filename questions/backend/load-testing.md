# è´Ÿè½½æµ‹è¯•é¢è¯•é¢˜

[â† è¿”å›åç«¯é¢è¯•é¢˜ç›®å½•](./README.md)

## ğŸ“‹ ç›®å½•

- [è´Ÿè½½æµ‹è¯•åŸºç¡€](#è´Ÿè½½æµ‹è¯•åŸºç¡€)
- [æµ‹è¯•å·¥å…·](#æµ‹è¯•å·¥å…·)
- [æµ‹è¯•ç­–ç•¥](#æµ‹è¯•ç­–ç•¥)
- [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
- [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

## ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹

```mermaid
mindmap
  root((è´Ÿè½½æµ‹è¯•))
    æµ‹è¯•ç±»å‹
      è´Ÿè½½æµ‹è¯•
      å‹åŠ›æµ‹è¯•
      å³°å€¼æµ‹è¯•
      å®¹é‡æµ‹è¯•
    æµ‹è¯•å·¥å…·
      JMeter
      Gatling
      K6
      Artillery
    æ€§èƒ½æŒ‡æ ‡
      å“åº”æ—¶é—´
      ååé‡
      å¹¶å‘ç”¨æˆ·æ•°
      é”™è¯¯ç‡
    æµ‹è¯•ç­–ç•¥
      æ¸è¿›å¼åŠ å‹
      çªå‘æµé‡
      æŒç»­è´Ÿè½½
```

## è´Ÿè½½æµ‹è¯•åŸºç¡€

### ğŸ’¡ åˆçº§é¢˜ç›®

#### 1. è´Ÿè½½æµ‹è¯•çš„ç±»å‹å’Œç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **è´Ÿè½½æµ‹è¯•**ï¼šéªŒè¯ç³»ç»Ÿåœ¨é¢„æœŸè´Ÿè½½ä¸‹çš„æ€§èƒ½
- **å‹åŠ›æµ‹è¯•**ï¼šæ‰¾åˆ°ç³»ç»Ÿçš„æ€§èƒ½æé™
- **å³°å€¼æµ‹è¯•**ï¼šæµ‹è¯•ç³»ç»Ÿå¤„ç†çªå‘æµé‡çš„èƒ½åŠ›
- **å®¹é‡æµ‹è¯•**ï¼šç¡®å®šç³»ç»Ÿçš„æœ€å¤§å¤„ç†èƒ½åŠ›
- **ç¨³å®šæ€§æµ‹è¯•**ï¼šé•¿æ—¶é—´è¿è¡ŒéªŒè¯ç³»ç»Ÿç¨³å®šæ€§

```python
import asyncio
import aiohttp
import time
import statistics
from dataclasses import dataclass
from typing import List, Dict, Any
import json

@dataclass
class TestResult:
    url: str
    method: str
    status_code: int
    response_time: float
    error: str = None
    timestamp: float = None

class LoadTester:
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.results = []
    
    async def single_request(self, session: aiohttp.ClientSession, 
                           endpoint: str, method: str = 'GET', 
                           data: Dict = None) -> TestResult:
        """æ‰§è¡Œå•ä¸ªè¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        try:
            async with session.request(method, url, json=data) as response:
                await response.text()  # è¯»å–å“åº”å†…å®¹
                response_time = time.time() - start_time
                
                return TestResult(
                    url=url,
                    method=method,
                    status_code=response.status,
                    response_time=response_time,
                    timestamp=start_time
                )
        except Exception as e:
            return TestResult(
                url=url,
                method=method,
                status_code=0,
                response_time=time.time() - start_time,
                error=str(e),
                timestamp=start_time
            )
    
    async def load_test(self, endpoint: str, concurrent_users: int, 
                       duration: int, method: str = 'GET', 
                       data: Dict = None) -> List[TestResult]:
        """æ‰§è¡Œè´Ÿè½½æµ‹è¯•"""
        print(f"å¼€å§‹è´Ÿè½½æµ‹è¯•: {concurrent_users} å¹¶å‘ç”¨æˆ·, æŒç»­ {duration} ç§’")
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            end_time = time.time() + duration
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            for _ in range(concurrent_users):
                task = asyncio.create_task(
                    self._user_simulation(session, endpoint, end_time, method, data)
                )
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks)
            
            # åˆå¹¶ç»“æœ
            all_results = []
            for user_results in results:
                all_results.extend(user_results)
            
            self.results = all_results
            return all_results
    
    async def _user_simulation(self, session: aiohttp.ClientSession, 
                              endpoint: str, end_time: float, 
                              method: str, data: Dict) -> List[TestResult]:
        """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·çš„è¡Œä¸º"""
        user_results = []
        
        while time.time() < end_time:
            result = await self.single_request(session, endpoint, method, data)
            user_results.append(result)
            
            # æ¨¡æ‹Ÿç”¨æˆ·æ€è€ƒæ—¶é—´
            await asyncio.sleep(0.1)
        
        return user_results
    
    def analyze_results(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not self.results:
            return {}
        
        # è¿‡æ»¤æˆåŠŸçš„è¯·æ±‚
        successful_results = [r for r in self.results if r.status_code == 200]
        failed_results = [r for r in self.results if r.status_code != 200]
        
        response_times = [r.response_time for r in successful_results]
        
        if not response_times:
            return {"error": "æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚"}
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        total_requests = len(self.results)
        successful_requests = len(successful_results)
        failed_requests = len(failed_results)
        
        # æ—¶é—´èŒƒå›´
        start_time = min(r.timestamp for r in self.results)
        end_time = max(r.timestamp for r in self.results)
        test_duration = end_time - start_time
        
        analysis = {
            "æ€»è¯·æ±‚æ•°": total_requests,
            "æˆåŠŸè¯·æ±‚æ•°": successful_requests,
            "å¤±è´¥è¯·æ±‚æ•°": failed_requests,
            "æˆåŠŸç‡": f"{successful_requests / total_requests * 100:.2f}%",
            "æµ‹è¯•æŒç»­æ—¶é—´": f"{test_duration:.2f}ç§’",
            "å¹³å‡å“åº”æ—¶é—´": f"{statistics.mean(response_times):.3f}ç§’",
            "ä¸­ä½æ•°å“åº”æ—¶é—´": f"{statistics.median(response_times):.3f}ç§’",
            "æœ€å°å“åº”æ—¶é—´": f"{min(response_times):.3f}ç§’",
            "æœ€å¤§å“åº”æ—¶é—´": f"{max(response_times):.3f}ç§’",
            "95ç™¾åˆ†ä½å“åº”æ—¶é—´": f"{statistics.quantiles(response_times, n=20)[18]:.3f}ç§’",
            "99ç™¾åˆ†ä½å“åº”æ—¶é—´": f"{statistics.quantiles(response_times, n=100)[98]:.3f}ç§’",
            "ååé‡": f"{successful_requests / test_duration:.2f} è¯·æ±‚/ç§’"
        }
        
        # é”™è¯¯åˆ†æ
        if failed_results:
            error_types = {}
            for result in failed_results:
                error_key = f"HTTP {result.status_code}"
                if result.error:
                    error_key = result.error
                error_types[error_key] = error_types.get(error_key, 0) + 1
            
            analysis["é”™è¯¯ç±»å‹"] = error_types
        
        return analysis

# ä½¿ç”¨ç¤ºä¾‹
async def basic_load_test():
    tester = LoadTester("http://localhost:8000")
    
    # æ‰§è¡Œè´Ÿè½½æµ‹è¯•
    results = await tester.load_test(
        endpoint="/api/users",
        concurrent_users=10,
        duration=30
    )
    
    # åˆ†æç»“æœ
    analysis = tester.analyze_results()
    print(json.dumps(analysis, indent=2, ensure_ascii=False))
```

### ğŸ”¥ ä¸­çº§é¢˜ç›®

#### 2. å¦‚ä½•è®¾è®¡æ¸è¿›å¼è´Ÿè½½æµ‹è¯•ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **é˜¶æ¢¯å¼åŠ å‹**ï¼šé€æ­¥å¢åŠ å¹¶å‘ç”¨æˆ·æ•°
- **æ€§èƒ½åŸºçº¿**ï¼šå»ºç«‹æ€§èƒ½åŸºå‡†
- **ç“¶é¢ˆè¯†åˆ«**ï¼šæ‰¾åˆ°æ€§èƒ½æ‹ç‚¹
- **å®¹é‡è§„åˆ’**ï¼šç¡®å®šç³»ç»Ÿå®¹é‡

```python
class ProgressiveLoadTester(LoadTester):
    def __init__(self, base_url: str):
        super().__init__(base_url)
        self.stage_results = {}
    
    async def progressive_test(self, endpoint: str, 
                             start_users: int = 1,
                             max_users: int = 100,
                             step_size: int = 10,
                             step_duration: int = 60) -> Dict[str, Any]:
        """æ‰§è¡Œæ¸è¿›å¼è´Ÿè½½æµ‹è¯•"""
        print(f"å¼€å§‹æ¸è¿›å¼è´Ÿè½½æµ‹è¯•: {start_users} -> {max_users} ç”¨æˆ·")
        
        current_users = start_users
        
        while current_users <= max_users:
            print(f"æµ‹è¯•é˜¶æ®µ: {current_users} å¹¶å‘ç”¨æˆ·")
            
            # æ‰§è¡Œå½“å‰é˜¶æ®µçš„æµ‹è¯•
            stage_results = await self.load_test(
                endpoint=endpoint,
                concurrent_users=current_users,
                duration=step_duration
            )
            
            # åˆ†æå½“å‰é˜¶æ®µç»“æœ
            stage_analysis = self.analyze_results()
            self.stage_results[current_users] = stage_analysis
            
            print(f"é˜¶æ®µ {current_users}: å¹³å‡å“åº”æ—¶é—´ {stage_analysis.get('å¹³å‡å“åº”æ—¶é—´', 'N/A')}")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½é˜ˆå€¼
            avg_response_time = statistics.mean([
                r.response_time for r in stage_results 
                if r.status_code == 200
            ]) if stage_results else float('inf')
            
            if avg_response_time > 2.0:  # 2ç§’é˜ˆå€¼
                print(f"æ€§èƒ½é˜ˆå€¼è¾¾åˆ°ï¼Œåœæ­¢æµ‹è¯•ã€‚å½“å‰ç”¨æˆ·æ•°: {current_users}")
                break
            
            current_users += step_size
            
            # æ¸…ç©ºç»“æœä¸ºä¸‹ä¸€é˜¶æ®µå‡†å¤‡
            self.results = []
        
        return self._analyze_progressive_results()
    
    def _analyze_progressive_results(self) -> Dict[str, Any]:
        """åˆ†ææ¸è¿›å¼æµ‹è¯•ç»“æœ"""
        if not self.stage_results:
            return {}
        
        # æå–å…³é”®æŒ‡æ ‡
        user_counts = list(self.stage_results.keys())
        response_times = []
        throughputs = []
        success_rates = []
        
        for users in user_counts:
            stage_data = self.stage_results[users]
            
            # æå–æ•°å€¼ï¼ˆå»é™¤å•ä½ï¼‰
            avg_time = float(stage_data.get('å¹³å‡å“åº”æ—¶é—´', '0').replace('ç§’', ''))
            throughput = float(stage_data.get('ååé‡', '0').replace(' è¯·æ±‚/ç§’', ''))
            success_rate = float(stage_data.get('æˆåŠŸç‡', '0%').replace('%', ''))
            
            response_times.append(avg_time)
            throughputs.append(throughput)
            success_rates.append(success_rate)
        
        # æ‰¾åˆ°æœ€ä½³æ€§èƒ½ç‚¹
        best_throughput_idx = throughputs.index(max(throughputs))
        optimal_users = user_counts[best_throughput_idx]
        
        # æ‰¾åˆ°æ€§èƒ½æ‹ç‚¹
        breaking_point = None
        for i in range(1, len(response_times)):
            if response_times[i] > response_times[i-1] * 1.5:  # å“åº”æ—¶é—´å¢é•¿50%
                breaking_point = user_counts[i]
                break
        
        return {
            "æµ‹è¯•é˜¶æ®µæ•°": len(user_counts),
            "æœ€å¤§å¹¶å‘ç”¨æˆ·æ•°": max(user_counts),
            "æœ€ä½³æ€§èƒ½ç‚¹": {
                "å¹¶å‘ç”¨æˆ·æ•°": optimal_users,
                "ååé‡": f"{throughputs[best_throughput_idx]:.2f} è¯·æ±‚/ç§’",
                "å¹³å‡å“åº”æ—¶é—´": f"{response_times[best_throughput_idx]:.3f}ç§’"
            },
            "æ€§èƒ½æ‹ç‚¹": breaking_point,
            "å„é˜¶æ®µè¯¦æƒ…": self.stage_results
        }

# å‹åŠ›æµ‹è¯•å®ç°
class StressTester(LoadTester):
    async def stress_test(self, endpoint: str, 
                         target_rps: int,  # ç›®æ ‡æ¯ç§’è¯·æ±‚æ•°
                         duration: int = 300) -> Dict[str, Any]:
        """æ‰§è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"å¼€å§‹å‹åŠ›æµ‹è¯•: ç›®æ ‡ {target_rps} RPS, æŒç»­ {duration} ç§’")
        
        # è®¡ç®—éœ€è¦çš„å¹¶å‘ç”¨æˆ·æ•°ï¼ˆä¼°ç®—ï¼‰
        estimated_users = target_rps * 2  # å‡è®¾æ¯ä¸ªç”¨æˆ·æ¯2ç§’å‘é€ä¸€ä¸ªè¯·æ±‚
        
        async with aiohttp.ClientSession() as session:
            # ä½¿ç”¨ä»¤ç‰Œæ¡¶ç®—æ³•æ§åˆ¶è¯·æ±‚é€Ÿç‡
            await self._rate_limited_test(
                session, endpoint, target_rps, duration
            )
        
        return self.analyze_results()
    
    async def _rate_limited_test(self, session: aiohttp.ClientSession,
                               endpoint: str, target_rps: int, duration: int):
        """ä½¿ç”¨é€Ÿç‡é™åˆ¶çš„æµ‹è¯•"""
        interval = 1.0 / target_rps  # è¯·æ±‚é—´éš”
        end_time = time.time() + duration
        
        tasks = []
        last_request_time = time.time()
        
        while time.time() < end_time:
            current_time = time.time()
            
            # æ§åˆ¶è¯·æ±‚é€Ÿç‡
            if current_time - last_request_time >= interval:
                task = asyncio.create_task(
                    self.single_request(session, endpoint)
                )
                tasks.append(task)
                last_request_time = current_time
            
            await asyncio.sleep(0.001)  # çŸ­æš‚ä¼‘çœ é¿å…CPUå ç”¨è¿‡é«˜
        
        # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
        self.results = await asyncio.gather(*tasks)

# å³°å€¼æµ‹è¯•å®ç°
class SpikeTester(LoadTester):
    async def spike_test(self, endpoint: str,
                        baseline_users: int = 10,
                        spike_users: int = 100,
                        spike_duration: int = 30,
                        total_duration: int = 300) -> Dict[str, Any]:
        """æ‰§è¡Œå³°å€¼æµ‹è¯•"""
        print(f"å¼€å§‹å³°å€¼æµ‹è¯•: åŸºçº¿ {baseline_users} ç”¨æˆ·, å³°å€¼ {spike_users} ç”¨æˆ·")
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            
            # åŸºçº¿ç”¨æˆ·ï¼ˆæŒç»­è¿è¡Œï¼‰
            for _ in range(baseline_users):
                task = asyncio.create_task(
                    self._baseline_user(session, endpoint, total_duration)
                )
                tasks.append(task)
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´åå¯åŠ¨å³°å€¼ç”¨æˆ·
            await asyncio.sleep(60)  # 1åˆ†é’Ÿåå¼€å§‹å³°å€¼
            
            spike_end_time = time.time() + spike_duration
            for _ in range(spike_users - baseline_users):
                task = asyncio.create_task(
                    self._spike_user(session, endpoint, spike_end_time)
                )
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks)
            
            # åˆå¹¶ç»“æœ
            all_results = []
            for user_results in results:
                all_results.extend(user_results)
            
            self.results = all_results
        
        return self._analyze_spike_results()
    
    async def _baseline_user(self, session: aiohttp.ClientSession,
                           endpoint: str, duration: int) -> List[TestResult]:
        """åŸºçº¿ç”¨æˆ·è¡Œä¸º"""
        results = []
        end_time = time.time() + duration
        
        while time.time() < end_time:
            result = await self.single_request(session, endpoint)
            result.timestamp = time.time()  # è®°å½•å®é™…æ—¶é—´æˆ³
            results.append(result)
            await asyncio.sleep(1)  # æ¯ç§’ä¸€ä¸ªè¯·æ±‚
        
        return results
    
    async def _spike_user(self, session: aiohttp.ClientSession,
                         endpoint: str, end_time: float) -> List[TestResult]:
        """å³°å€¼ç”¨æˆ·è¡Œä¸º"""
        results = []
        
        while time.time() < end_time:
            result = await self.single_request(session, endpoint)
            result.timestamp = time.time()
            results.append(result)
            await asyncio.sleep(0.1)  # æ›´é¢‘ç¹çš„è¯·æ±‚
        
        return results
    
    def _analyze_spike_results(self) -> Dict[str, Any]:
        """åˆ†æå³°å€¼æµ‹è¯•ç»“æœ"""
        if not self.results:
            return {}
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_results = sorted(self.results, key=lambda x: x.timestamp)
        
        # æ‰¾åˆ°å³°å€¼å¼€å§‹æ—¶é—´ï¼ˆè¯·æ±‚é¢‘ç‡æ˜æ˜¾å¢åŠ çš„æ—¶é—´ç‚¹ï¼‰
        spike_start = self._detect_spike_start(sorted_results)
        
        # åˆ†æå³°å€¼å‰åçš„æ€§èƒ½
        pre_spike = [r for r in sorted_results if r.timestamp < spike_start]
        during_spike = [r for r in sorted_results if r.timestamp >= spike_start]
        
        pre_spike_analysis = self._analyze_period(pre_spike, "å³°å€¼å‰")
        spike_analysis = self._analyze_period(during_spike, "å³°å€¼æœŸé—´")
        
        return {
            "å³°å€¼å¼€å§‹æ—¶é—´": spike_start,
            "å³°å€¼å‰æ€§èƒ½": pre_spike_analysis,
            "å³°å€¼æœŸé—´æ€§èƒ½": spike_analysis,
            "æ€§èƒ½å½±å“": self._calculate_performance_impact(
                pre_spike_analysis, spike_analysis
            )
        }
    
    def _detect_spike_start(self, sorted_results: List[TestResult]) -> float:
        """æ£€æµ‹å³°å€¼å¼€å§‹æ—¶é—´"""
        if len(sorted_results) < 10:
            return sorted_results[0].timestamp
        
        # è®¡ç®—æ¯ç§’çš„è¯·æ±‚æ•°
        time_buckets = {}
        for result in sorted_results:
            bucket = int(result.timestamp)
            time_buckets[bucket] = time_buckets.get(bucket, 0) + 1
        
        # æ‰¾åˆ°è¯·æ±‚æ•°æ˜æ˜¾å¢åŠ çš„æ—¶é—´ç‚¹
        buckets = sorted(time_buckets.keys())
        for i in range(1, len(buckets)):
            current_rps = time_buckets[buckets[i]]
            previous_rps = time_buckets[buckets[i-1]]
            
            if current_rps > previous_rps * 2:  # è¯·æ±‚æ•°ç¿»å€
                return float(buckets[i])
        
        return sorted_results[0].timestamp
    
    def _analyze_period(self, results: List[TestResult], period_name: str) -> Dict:
        """åˆ†æç‰¹å®šæ—¶æœŸçš„æ€§èƒ½"""
        if not results:
            return {}
        
        successful = [r for r in results if r.status_code == 200]
        response_times = [r.response_time for r in successful]
        
        if not response_times:
            return {"é”™è¯¯": "æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚"}
        
        return {
            "æ—¶æœŸ": period_name,
            "è¯·æ±‚æ€»æ•°": len(results),
            "æˆåŠŸè¯·æ±‚æ•°": len(successful),
            "å¹³å‡å“åº”æ—¶é—´": f"{statistics.mean(response_times):.3f}ç§’",
            "95ç™¾åˆ†ä½å“åº”æ—¶é—´": f"{statistics.quantiles(response_times, n=20)[18]:.3f}ç§’"
        }
    
    def _calculate_performance_impact(self, pre_spike: Dict, during_spike: Dict) -> Dict:
        """è®¡ç®—æ€§èƒ½å½±å“"""
        if not pre_spike or not during_spike:
            return {}
        
        try:
            pre_avg = float(pre_spike["å¹³å‡å“åº”æ—¶é—´"].replace("ç§’", ""))
            spike_avg = float(during_spike["å¹³å‡å“åº”æ—¶é—´"].replace("ç§’", ""))
            
            impact = (spike_avg - pre_avg) / pre_avg * 100
            
            return {
                "å“åº”æ—¶é—´å¢é•¿": f"{impact:.1f}%",
                "æ€§èƒ½é€€åŒ–ç¨‹åº¦": "ä¸¥é‡" if impact > 100 else "ä¸­ç­‰" if impact > 50 else "è½»å¾®"
            }
        except:
            return {"é”™è¯¯": "æ— æ³•è®¡ç®—æ€§èƒ½å½±å“"}

# ä½¿ç”¨ç¤ºä¾‹
async def comprehensive_load_testing():
    base_url = "http://localhost:8000"
    
    # 1. æ¸è¿›å¼è´Ÿè½½æµ‹è¯•
    print("=== æ¸è¿›å¼è´Ÿè½½æµ‹è¯• ===")
    progressive_tester = ProgressiveLoadTester(base_url)
    progressive_results = await progressive_tester.progressive_test(
        endpoint="/api/users",
        start_users=5,
        max_users=50,
        step_size=5,
        step_duration=30
    )
    print(json.dumps(progressive_results, indent=2, ensure_ascii=False))
    
    # 2. å‹åŠ›æµ‹è¯•
    print("\n=== å‹åŠ›æµ‹è¯• ===")
    stress_tester = StressTester(base_url)
    stress_results = await stress_tester.stress_test(
        endpoint="/api/users",
        target_rps=100,
        duration=120
    )
    print(json.dumps(stress_results, indent=2, ensure_ascii=False))
    
    # 3. å³°å€¼æµ‹è¯•
    print("\n=== å³°å€¼æµ‹è¯• ===")
    spike_tester = SpikeTester(base_url)
    spike_results = await spike_tester.spike_test(
        endpoint="/api/users",
        baseline_users=10,
        spike_users=50,
        spike_duration=60,
        total_duration=300
    )
    print(json.dumps(spike_results, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(comprehensive_load_testing())
```

## æµ‹è¯•å·¥å…·

### ğŸ”¥ ä¸­çº§é¢˜ç›®

#### 3. ä¸»æµè´Ÿè½½æµ‹è¯•å·¥å…·çš„ç‰¹ç‚¹å’Œé€‰æ‹©ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **JMeter**ï¼šGUIç•Œé¢ï¼ŒåŠŸèƒ½å…¨é¢ï¼Œé€‚åˆå¤æ‚åœºæ™¯
- **Gatling**ï¼šé«˜æ€§èƒ½ï¼ŒScalaç¼–å†™ï¼Œé€‚åˆå¤§è§„æ¨¡æµ‹è¯•
- **K6**ï¼šJavaScriptç¼–å†™ï¼Œäº‘åŸç”Ÿï¼Œæ˜“äºCI/CDé›†æˆ
- **Artillery**ï¼šNode.jsç¼–å†™ï¼Œç®€å•æ˜“ç”¨ï¼Œé€‚åˆAPIæµ‹è¯•

```yaml
# K6 æµ‹è¯•è„šæœ¬ç¤ºä¾‹
# test-script.js
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

// è‡ªå®šä¹‰æŒ‡æ ‡
export let errorRate = new Rate('errors');

export let options = {
  stages: [
    { duration: '2m', target: 10 }, // 2åˆ†é’Ÿå†…å¢åŠ åˆ°10ä¸ªç”¨æˆ·
    { duration: '5m', target: 10 }, // ä¿æŒ10ä¸ªç”¨æˆ·5åˆ†é’Ÿ
    { duration: '2m', target: 20 }, // 2åˆ†é’Ÿå†…å¢åŠ åˆ°20ä¸ªç”¨æˆ·
    { duration: '5m', target: 20 }, // ä¿æŒ20ä¸ªç”¨æˆ·5åˆ†é’Ÿ
    { duration: '2m', target: 0 },  // 2åˆ†é’Ÿå†…å‡å°‘åˆ°0ä¸ªç”¨æˆ·
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%çš„è¯·æ±‚å“åº”æ—¶é—´å°äº500ms
    http_req_failed: ['rate<0.1'],    // é”™è¯¯ç‡å°äº10%
  },
};

export default function() {
  let response = http.get('http://localhost:8000/api/users');
  
  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
  
  errorRate.add(response.status !== 200);
  
  sleep(1);
}
```

```xml
<!-- JMeter æµ‹è¯•è®¡åˆ’ç¤ºä¾‹ -->
<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2">
  <hashTree>
    <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="API Load Test">
      <elementProp name="TestPlan.arguments" elementType="Arguments" guiclass="ArgumentsPanel">
        <collectionProp name="Arguments.arguments"/>
      </elementProp>
      <stringProp name="TestPlan.user_define_classpath"></stringProp>
      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
      <boolProp name="TestPlan.functional_mode">false</boolProp>
    </TestPlan>
    <hashTree>
      <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="User Group">
        <stringProp name="ThreadGroup.on_sample_error">continue</stringProp>
        <elementProp name="ThreadGroup.main_controller" elementType="LoopController">
          <boolProp name="LoopController.continue_forever">false</boolProp>
          <stringProp name="LoopController.loops">10</stringProp>
        </elementProp>
        <stringProp name="ThreadGroup.num_threads">50</stringProp>
        <stringProp name="ThreadGroup.ramp_time">60</stringProp>
      </ThreadGroup>
      <hashTree>
        <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="Get Users">
          <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
            <collectionProp name="Arguments.arguments"/>
          </elementProp>
          <stringProp name="HTTPSampler.domain">localhost</stringProp>
          <stringProp name="HTTPSampler.port">8000</stringProp>
          <stringProp name="HTTPSampler.path">/api/users</stringProp>
          <stringProp name="HTTPSampler.method">GET</stringProp>
        </HTTPSamplerProxy>
      </hashTree>
    </hashTree>
  </hashTree>
</jmeterTestPlan>
```

## ğŸ”— ç›¸å…³é“¾æ¥

- [â† è¿”å›åç«¯é¢è¯•é¢˜ç›®å½•](./README.md)
- [æ€§èƒ½ä¼˜åŒ–é¢è¯•é¢˜](./performance-optimization.md)
- [ç›‘æ§ä¸è°ƒè¯•é¢è¯•é¢˜](./monitoring-debugging.md)
- [ç³»ç»Ÿè®¾è®¡é¢è¯•é¢˜](../system-design/README.md)

---

*æŒæ¡è´Ÿè½½æµ‹è¯•æŠ€èƒ½ï¼Œç¡®ä¿ç³»ç»Ÿæ€§èƒ½å’Œç¨³å®šæ€§* ğŸš€ 