# ä¼ä¸šçº§ç›‘æ§ä½“ç³»æ¶æ„å®Œæ•´å®ç°

## ğŸ¯ è§£å†³æ–¹æ¡ˆæ¦‚è¿°

ä¼ä¸šçº§ç›‘æ§ä½“ç³»æ˜¯ä¿éšœå¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿç¨³å®šè¿è¡Œçš„æ ¸å¿ƒåŸºç¡€è®¾æ–½ã€‚æœ¬æ–¹æ¡ˆæ·±å…¥åˆ†æç›‘æ§ç³»ç»Ÿçš„è®¾è®¡åŸç†ï¼Œæä¾›ä»æŒ‡æ ‡æ”¶é›†ã€æ•°æ®å­˜å‚¨ã€å¯è§†åŒ–å±•ç¤ºåˆ°æ™ºèƒ½å‘Šè­¦çš„å®Œæ•´æŠ€æœ¯å®ç°ï¼Œé‡ç‚¹è§£å†³æµ·é‡ç›‘æ§æ•°æ®çš„å¤„ç†ã€å®æ—¶å‘Šè­¦çš„ç²¾å‡†æ€§å’Œç›‘æ§ç³»ç»Ÿè‡ªèº«çš„é«˜å¯ç”¨æ€§æŒ‘æˆ˜ã€‚

## ğŸ’¡ æ ¸å¿ƒé—®é¢˜åˆ†æ

### ä¼ä¸šçº§ç›‘æ§çš„æŠ€æœ¯æŒ‘æˆ˜

**ä¸šåŠ¡èƒŒæ™¯**ï¼šç°ä»£ä¼ä¸šçš„ITåŸºç¡€è®¾æ–½æ—¥ç›Šå¤æ‚ï¼Œå¾®æœåŠ¡æ¶æ„ã€å®¹å™¨åŒ–éƒ¨ç½²ã€å¤šäº‘ç¯å¢ƒç­‰æŠ€æœ¯æ ˆè¦æ±‚ç›‘æ§ç³»ç»Ÿå…·å¤‡æ›´å¼ºçš„é€‚åº”æ€§å’Œæ‰©å±•æ€§ã€‚

**æŠ€æœ¯éš¾ç‚¹**ï¼š
- **æµ·é‡æ•°æ®å¤„ç†**ï¼šæ¯ç§’ç™¾ä¸‡çº§æŒ‡æ ‡æ•°æ®çš„å®æ—¶æ”¶é›†å’Œå¤„ç†
- **å¤šç»´åº¦ç›‘æ§**ï¼šç³»ç»ŸæŒ‡æ ‡ã€ä¸šåŠ¡æŒ‡æ ‡ã€ç”¨æˆ·ä½“éªŒæŒ‡æ ‡çš„ç»Ÿä¸€ç®¡ç†
- **æ™ºèƒ½å‘Šè­¦**ï¼šå‡å°‘å‘Šè­¦å™ªéŸ³ï¼Œæé«˜å‘Šè­¦çš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§
- **é«˜å¯ç”¨ä¿éšœ**ï¼šç›‘æ§ç³»ç»Ÿè‡ªèº«çš„å¯é æ€§å’Œå®¹é”™èƒ½åŠ›

## ğŸ“ é¢˜ç›®1ï¼šä¼ä¸šçº§ç›‘æ§ä½“ç³»çš„æ¶æ„è®¾è®¡å’Œå®ç°

### è§£å†³æ–¹æ¡ˆæ€è·¯åˆ†æ

#### 1. ç›‘æ§æ¶æ„è®¾è®¡ç­–ç•¥

**ä¸ºä»€ä¹ˆé€‰æ‹©åˆ†å±‚ç›‘æ§æ¶æ„ï¼Ÿ**
- **æ•°æ®æ”¶é›†å±‚**ï¼šæ”¯æŒå¤šç§æ•°æ®æºå’Œåè®®ï¼Œç¡®ä¿æ•°æ®æ”¶é›†çš„å®Œæ•´æ€§
- **æ•°æ®å¤„ç†å±‚**ï¼šå®ç°æ•°æ®æ¸…æ´—ã€èšåˆå’Œè®¡ç®—ï¼Œæé«˜æ•°æ®è´¨é‡
- **å­˜å‚¨å±‚**ï¼šé‡‡ç”¨æ—¶åºæ•°æ®åº“ï¼Œä¼˜åŒ–æ—¶é—´åºåˆ—æ•°æ®çš„å­˜å‚¨å’ŒæŸ¥è¯¢
- **å±•ç¤ºå±‚**ï¼šæä¾›çµæ´»çš„å¯è§†åŒ–å’ŒæŸ¥è¯¢ç•Œé¢ï¼Œæ»¡è¶³ä¸åŒè§’è‰²éœ€æ±‚

#### 2. æ—¶åºæ•°æ®åº“é€‰æ‹©åŸç†

**Prometheus + InfluxDBæ··åˆå­˜å‚¨ç­–ç•¥**ï¼š
- **Prometheusä¼˜åŠ¿**ï¼šå¼ºå¤§çš„æŸ¥è¯¢è¯­è¨€PromQLï¼Œå®Œå–„çš„ç”Ÿæ€ç³»ç»Ÿ
- **InfluxDBä¼˜åŠ¿**ï¼šé«˜æ€§èƒ½çš„æ—¶åºæ•°æ®å­˜å‚¨ï¼Œæ”¯æŒSQLæŸ¥è¯¢
- **å­˜å‚¨åˆ†å±‚**ï¼šçŸ­æœŸæ•°æ®ç”¨Prometheusï¼Œé•¿æœŸæ•°æ®ç”¨InfluxDB
- **æ•°æ®åŒæ­¥**ï¼šé€šè¿‡Remote Writeåè®®å®ç°æ•°æ®åŒæ­¥

#### 3. æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿè®¾è®¡æ€è·¯

**å¤šçº§å‘Šè­¦å’Œé™å™ªæœºåˆ¶**ï¼š
- **åŸºç¡€å‘Šè­¦**ï¼šåŸºäºé˜ˆå€¼çš„ä¼ ç»Ÿå‘Šè­¦æœºåˆ¶
- **æ™ºèƒ½å‘Šè­¦**ï¼šåŸºäºæœºå™¨å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•
- **å‘Šè­¦èšåˆ**ï¼šç›¸å…³å‘Šè­¦çš„æ™ºèƒ½åˆå¹¶å’Œå»é‡
- **å‘Šè­¦å‡çº§**ï¼šåŸºäºä¸¥é‡ç¨‹åº¦å’Œå“åº”æ—¶é—´çš„è‡ªåŠ¨å‡çº§

### ä»£ç å®ç°è¦ç‚¹

#### ç›‘æ§æ•°æ®æ”¶é›†å™¨å®ç°

```python
"""
ä¼ä¸šçº§ç›‘æ§æ•°æ®æ”¶é›†å™¨
è®¾è®¡åŸç†ï¼š
1. æ’ä»¶åŒ–æ¶æ„ï¼šæ”¯æŒå¤šç§æ•°æ®æºçš„åŠ¨æ€åŠ è½½
2. å¼‚æ­¥å¤„ç†ï¼šä½¿ç”¨asyncioæé«˜æ•°æ®æ”¶é›†æ•ˆç‡
3. æ•°æ®ç¼“å†²ï¼šæœ¬åœ°ç¼“å­˜æœºåˆ¶ä¿è¯æ•°æ®ä¸ä¸¢å¤±
4. è‡ªåŠ¨é‡è¯•ï¼šç½‘ç»œå¼‚å¸¸æ—¶çš„é‡è¯•å’Œæ¢å¤æœºåˆ¶
"""

import asyncio
import aiohttp
import json
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod
import logging
from collections import deque
import yaml

@dataclass
class MetricData:
    """ç›‘æ§æŒ‡æ ‡æ•°æ®ç»“æ„"""
    name: str
    value: float
    timestamp: float
    labels: Dict[str, str]
    instance: str
    
    def to_prometheus_format(self) -> str:
        """è½¬æ¢ä¸ºPrometheusæ ¼å¼"""
        labels_str = ','.join([f'{k}="{v}"' for k, v in self.labels.items()])
        return f'{self.name}{{{labels_str}}} {self.value} {int(self.timestamp * 1000)}'

class MetricCollector(ABC):
    """ç›‘æ§æŒ‡æ ‡æ”¶é›†å™¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def collect(self) -> List[MetricData]:
        """æ”¶é›†ç›‘æ§æŒ‡æ ‡"""
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """è·å–æ”¶é›†å™¨åç§°"""
        pass

class SystemMetricsCollector(MetricCollector):
    """ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, instance_id: str):
        self.instance_id = instance_id
        
    async def collect(self) -> List[MetricData]:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        import psutil
        
        metrics = []
        current_time = time.time()
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        metrics.append(MetricData(
            name="system_cpu_usage_percent",
            value=cpu_percent,
            timestamp=current_time,
            labels={"type": "cpu"},
            instance=self.instance_id
        ))
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        metrics.append(MetricData(
            name="system_memory_usage_bytes",
            value=memory.used,
            timestamp=current_time,
            labels={"type": "memory"},
            instance=self.instance_id
        ))
        
        metrics.append(MetricData(
            name="system_memory_usage_percent",
            value=memory.percent,
            timestamp=current_time,
            labels={"type": "memory"},
            instance=self.instance_id
        ))
        
        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk = psutil.disk_usage('/')
        metrics.append(MetricData(
            name="system_disk_usage_bytes",
            value=disk.used,
            timestamp=current_time,
            labels={"type": "disk", "mount": "/"},
            instance=self.instance_id
        ))
        
        # ç½‘ç»œI/O
        network = psutil.net_io_counters()
        metrics.append(MetricData(
            name="system_network_bytes_sent_total",
            value=network.bytes_sent,
            timestamp=current_time,
            labels={"type": "network", "direction": "sent"},
            instance=self.instance_id
        ))
        
        metrics.append(MetricData(
            name="system_network_bytes_recv_total",
            value=network.bytes_recv,
            timestamp=current_time,
            labels={"type": "network", "direction": "received"},
            instance=self.instance_id
        ))
        
        return metrics
    
    def get_name(self) -> str:
        return "system_metrics"

class ApplicationMetricsCollector(MetricCollector):
    """åº”ç”¨æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, app_name: str, instance_id: str):
        self.app_name = app_name
        self.instance_id = instance_id
        self.request_count = 0
        self.error_count = 0
        self.response_times = deque(maxlen=1000)
        
    async def collect(self) -> List[MetricData]:
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        metrics = []
        current_time = time.time()
        
        # è¯·æ±‚è®¡æ•°
        metrics.append(MetricData(
            name="app_requests_total",
            value=self.request_count,
            timestamp=current_time,
            labels={"app": self.app_name, "type": "requests"},
            instance=self.instance_id
        ))
        
        # é”™è¯¯è®¡æ•°
        metrics.append(MetricData(
            name="app_errors_total",
            value=self.error_count,
            timestamp=current_time,
            labels={"app": self.app_name, "type": "errors"},
            instance=self.instance_id
        ))
        
        # å¹³å‡å“åº”æ—¶é—´
        if self.response_times:
            avg_response_time = sum(self.response_times) / len(self.response_times)
            metrics.append(MetricData(
                name="app_response_time_avg_ms",
                value=avg_response_time,
                timestamp=current_time,
                labels={"app": self.app_name, "type": "performance"},
                instance=self.instance_id
            ))
            
            # 95åˆ†ä½å“åº”æ—¶é—´
            sorted_times = sorted(self.response_times)
            p95_response_time = sorted_times[int(len(sorted_times) * 0.95)]
            metrics.append(MetricData(
                name="app_response_time_p95_ms",
                value=p95_response_time,
                timestamp=current_time,
                labels={"app": self.app_name, "type": "performance"},
                instance=self.instance_id
            ))
        
        return metrics
    
    def record_request(self, response_time_ms: float, is_error: bool = False):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.request_count += 1
        self.response_times.append(response_time_ms)
        if is_error:
            self.error_count += 1
    
    def get_name(self) -> str:
        return f"app_metrics_{self.app_name}"

class MonitoringAgent:
    """ç›‘æ§ä»£ç†ä¸»ç±»"""
    
    def __init__(self, config_file: str):
        self.config = self._load_config(config_file)
        self.collectors: List[MetricCollector] = []
        self.running = False
        self.data_buffer = deque(maxlen=10000)
        self.logger = logging.getLogger(__name__)
        
    def _load_config(self, config_file: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_file, 'r') as f:
            return yaml.safe_load(f)
    
    def add_collector(self, collector: MetricCollector):
        """æ·»åŠ æŒ‡æ ‡æ”¶é›†å™¨"""
        self.collectors.append(collector)
        self.logger.info(f"Added collector: {collector.get_name()}")
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§ä»£ç†"""
        self.running = True
        self.logger.info("Starting monitoring agent...")
        
        # å¯åŠ¨æ•°æ®æ”¶é›†ä»»åŠ¡
        collect_task = asyncio.create_task(self._collect_loop())
        
        # å¯åŠ¨æ•°æ®å‘é€ä»»åŠ¡
        send_task = asyncio.create_task(self._send_loop())
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.gather(collect_task, send_task)
    
    async def stop(self):
        """åœæ­¢ç›‘æ§ä»£ç†"""
        self.running = False
        self.logger.info("Stopping monitoring agent...")
    
    async def _collect_loop(self):
        """æ•°æ®æ”¶é›†å¾ªç¯"""
        while self.running:
            try:
                # å¹¶å‘æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
                tasks = [collector.collect() for collector in self.collectors]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # å¤„ç†æ”¶é›†ç»“æœ
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        self.logger.error(f"Collector {self.collectors[i].get_name()} failed: {result}")
                    else:
                        for metric in result:
                            self.data_buffer.append(metric)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ”¶é›†
                await asyncio.sleep(self.config.get('collect_interval', 15))
                
            except Exception as e:
                self.logger.error(f"Collect loop error: {e}")
                await asyncio.sleep(5)
    
    async def _send_loop(self):
        """æ•°æ®å‘é€å¾ªç¯"""
        while self.running:
            try:
                if self.data_buffer:
                    # æ‰¹é‡å‘é€æ•°æ®
                    batch_size = self.config.get('batch_size', 100)
                    batch = []
                    
                    for _ in range(min(batch_size, len(self.data_buffer))):
                        if self.data_buffer:
                            batch.append(self.data_buffer.popleft())
                    
                    if batch:
                        await self._send_metrics(batch)
                
                await asyncio.sleep(self.config.get('send_interval', 10))
                
            except Exception as e:
                self.logger.error(f"Send loop error: {e}")
                await asyncio.sleep(5)
    
    async def _send_metrics(self, metrics: List[MetricData]):
        """å‘é€æŒ‡æ ‡æ•°æ®åˆ°ç›‘æ§æœåŠ¡å™¨"""
        prometheus_url = self.config.get('prometheus_remote_write_url')
        influxdb_url = self.config.get('influxdb_url')
        
        # å‘é€åˆ°Prometheus
        if prometheus_url:
            await self._send_to_prometheus(metrics, prometheus_url)
        
        # å‘é€åˆ°InfluxDB
        if influxdb_url:
            await self._send_to_influxdb(metrics, influxdb_url)
    
    async def _send_to_prometheus(self, metrics: List[MetricData], url: str):
        """å‘é€æ•°æ®åˆ°Prometheus"""
        try:
            # è½¬æ¢ä¸ºPrometheusæ ¼å¼
            data = '\n'.join([metric.to_prometheus_format() for metric in metrics])
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    data=data,
                    headers={'Content-Type': 'text/plain'},
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        self.logger.debug(f"Sent {len(metrics)} metrics to Prometheus")
                    else:
                        self.logger.error(f"Failed to send to Prometheus: {response.status}")
                        
        except Exception as e:
            self.logger.error(f"Error sending to Prometheus: {e}")
    
    async def _send_to_influxdb(self, metrics: List[MetricData], url: str):
        """å‘é€æ•°æ®åˆ°InfluxDB"""
        try:
            # è½¬æ¢ä¸ºLine Protocolæ ¼å¼
            lines = []
            for metric in metrics:
                labels_str = ','.join([f'{k}={v}' for k, v in metric.labels.items()])
                line = f"{metric.name},{labels_str} value={metric.value} {int(metric.timestamp * 1000000000)}"
                lines.append(line)
            
            data = '\n'.join(lines)
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{url}/write",
                    data=data,
                    headers={'Content-Type': 'text/plain'},
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 204:
                        self.logger.debug(f"Sent {len(metrics)} metrics to InfluxDB")
                    else:
                        self.logger.error(f"Failed to send to InfluxDB: {response.status}")
                        
        except Exception as e:
            self.logger.error(f"Error sending to InfluxDB: {e}")

# æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿå®ç°
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    
    def __init__(self, name: str, query: str, threshold: float, 
                 severity: str, duration: int = 60):
        self.name = name
        self.query = query
        self.threshold = threshold
        self.severity = severity
        self.duration = duration
        self.last_alert_time = 0
        
    def should_alert(self, value: float, current_time: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘Šè­¦"""
        if value > self.threshold:
            if current_time - self.last_alert_time > self.duration:
                self.last_alert_time = current_time
                return True
        return False

class IntelligentAlertManager:
    """æ™ºèƒ½å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.rules: List[AlertRule] = []
        self.alert_history = deque(maxlen=1000)
        self.suppression_rules = {}
        
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        self.rules.append(rule)
    
    async def evaluate_alerts(self, metrics: List[MetricData]):
        """è¯„ä¼°å‘Šè­¦æ¡ä»¶"""
        current_time = time.time()
        
        for rule in self.rules:
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ‰§è¡ŒPromQLæŸ¥è¯¢
            for metric in metrics:
                if metric.name in rule.query:
                    if rule.should_alert(metric.value, current_time):
                        await self._send_alert(rule, metric)
    
    async def _send_alert(self, rule: AlertRule, metric: MetricData):
        """å‘é€å‘Šè­¦"""
        alert = {
            'rule_name': rule.name,
            'severity': rule.severity,
            'metric_name': metric.name,
            'value': metric.value,
            'threshold': rule.threshold,
            'instance': metric.instance,
            'timestamp': metric.timestamp,
            'labels': metric.labels
        }
        
        self.alert_history.append(alert)
        
        # å‘é€åˆ°å‘Šè­¦é€šé“ï¼ˆé’‰é’‰ã€é‚®ä»¶ã€çŸ­ä¿¡ç­‰ï¼‰
        await self._notify_alert(alert)
    
    async def _notify_alert(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # å®ç°å…·ä½“çš„é€šçŸ¥é€»è¾‘
        print(f"ğŸš¨ ALERT: {alert['rule_name']} - {alert['metric_name']} = {alert['value']}")

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºç›‘æ§ä»£ç†
    agent = MonitoringAgent('monitoring_config.yaml')
    
    # æ·»åŠ ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨
    system_collector = SystemMetricsCollector("server-01")
    agent.add_collector(system_collector)
    
    # æ·»åŠ åº”ç”¨æŒ‡æ ‡æ”¶é›†å™¨
    app_collector = ApplicationMetricsCollector("web-service", "server-01")
    agent.add_collector(app_collector)
    
    # åˆ›å»ºå‘Šè­¦ç®¡ç†å™¨
    alert_manager = IntelligentAlertManager()
    
    # æ·»åŠ å‘Šè­¦è§„åˆ™
    cpu_rule = AlertRule(
        name="High CPU Usage",
        query="system_cpu_usage_percent",
        threshold=80.0,
        severity="warning",
        duration=300  # 5åˆ†é’Ÿ
    )
    alert_manager.add_rule(cpu_rule)
    
    memory_rule = AlertRule(
        name="High Memory Usage",
        query="system_memory_usage_percent",
        threshold=90.0,
        severity="critical",
        duration=60  # 1åˆ†é’Ÿ
    )
    alert_manager.add_rule(memory_rule)
    
    # å¯åŠ¨ç›‘æ§ç³»ç»Ÿ
    try:
        await agent.start()
    except KeyboardInterrupt:
        await agent.stop()

if __name__ == "__main__":
    asyncio.run(main())
```

#### é…ç½®æ–‡ä»¶ç¤ºä¾‹ (monitoring_config.yaml)

```yaml
# ç›‘æ§ä»£ç†é…ç½®
collect_interval: 15  # æ•°æ®æ”¶é›†é—´éš”ï¼ˆç§’ï¼‰
send_interval: 10     # æ•°æ®å‘é€é—´éš”ï¼ˆç§’ï¼‰
batch_size: 100       # æ‰¹é‡å‘é€å¤§å°

# Prometheusé…ç½®
prometheus_remote_write_url: "http://prometheus:9090/api/v1/write"

# InfluxDBé…ç½®
influxdb_url: "http://influxdb:8086"
influxdb_database: "monitoring"

# æ—¥å¿—é…ç½®
logging:
  level: INFO
  file: "/var/log/monitoring-agent.log"

# æ”¶é›†å™¨é…ç½®
collectors:
  system:
    enabled: true
    interval: 15
  
  application:
    enabled: true
    interval: 30
    
# å‘Šè­¦é…ç½®
alerting:
  enabled: true
  webhook_url: "http://alertmanager:9093/api/v1/alerts"
```

## ğŸ¯ é¢è¯•è¦ç‚¹æ€»ç»“

### æŠ€æœ¯æ·±åº¦ä½“ç°
- **æ¶æ„è®¾è®¡èƒ½åŠ›**ï¼šå±•ç¤ºåˆ†å±‚ç›‘æ§æ¶æ„çš„è®¾è®¡æ€è·¯å’ŒæŠ€æœ¯é€‰å‹ä¾æ®
- **æ•°æ®å¤„ç†æŠ€æœ¯**ï¼šæŒæ¡æ—¶åºæ•°æ®çš„å­˜å‚¨ã€æŸ¥è¯¢å’Œèšåˆä¼˜åŒ–æŠ€æœ¯
- **é«˜å¯ç”¨è®¾è®¡**ï¼šç›‘æ§ç³»ç»Ÿè‡ªèº«çš„å®¹é”™å’Œæ•…éšœæ¢å¤æœºåˆ¶
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæµ·é‡æ•°æ®åœºæ™¯ä¸‹çš„æ€§èƒ½è°ƒä¼˜å’Œèµ„æºç®¡ç†

### ç”Ÿäº§å®è·µç»éªŒ
- **ç›‘æ§ä½“ç³»å»ºè®¾**ï¼šä»é›¶æ­å»ºä¼ä¸šçº§ç›‘æ§ç³»ç»Ÿçš„å®Œæ•´ç»éªŒ
- **å‘Šè­¦ç­–ç•¥ä¼˜åŒ–**ï¼šåŸºäºä¸šåŠ¡ç‰¹ç‚¹è®¾è®¡ç²¾å‡†å‘Šè­¦ï¼Œå‡å°‘å™ªéŸ³å¹²æ‰°
- **æ•…éšœå“åº”æœºåˆ¶**ï¼šå¿«é€Ÿå®šä½å’Œè§£å†³ç”Ÿäº§ç¯å¢ƒç›‘æ§é—®é¢˜
- **æˆæœ¬æ§åˆ¶**ï¼šç›‘æ§ç³»ç»Ÿçš„èµ„æºä½¿ç”¨ä¼˜åŒ–å’Œæˆæœ¬ç®¡ç†

### é¢è¯•å›ç­”è¦ç‚¹
- **ç³»ç»Ÿæ€ç»´**ï¼šä»ä¸šåŠ¡éœ€æ±‚å‡ºå‘ï¼Œè®¾è®¡å®Œæ•´çš„ç›‘æ§è§£å†³æ–¹æ¡ˆ
- **æŠ€æœ¯æ·±åº¦**ï¼šæ·±å…¥ç†è§£ç›‘æ§ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯å’Œå®ç°åŸç†
- **å®æˆ˜ç»éªŒ**ï¼šç»“åˆå…·ä½“é¡¹ç›®ç»éªŒï¼Œå±•ç¤ºç›‘æ§ç³»ç»Ÿçš„ä»·å€¼å’Œæ•ˆæœ
- **æŒç»­æ”¹è¿›**ï¼šåŸºäºç›‘æ§æ•°æ®è¿›è¡Œç³»ç»Ÿä¼˜åŒ–å’Œä¸šåŠ¡æ”¹è¿›çš„æ€è·¯

[â† è¿”å›ç›‘æ§ä¸è°ƒè¯•é¢è¯•é¢˜](../../questions/backend/monitoring-debugging.md) 